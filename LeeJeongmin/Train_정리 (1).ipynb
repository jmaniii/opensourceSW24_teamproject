{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:43.378639Z",
     "start_time": "2022-01-24T01:42:41.159378Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import Input,Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Activation,Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization,add,Add,multiply,Lambda\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, History, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import backend as K\n",
    "from keras_unet_collection import models, base, utils,losses\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:47.822057Z",
     "start_time": "2022-01-24T01:42:47.807066Z"
    }
   },
   "outputs": [],
   "source": [
    "# 주어진 path에서 이미지와 mask를 불러와 형식을 맞춰주고, pixel값을 0~1 사이로 normalize 해주는 함수\n",
    "# return된 이미지의 shape은 (N,512,512,3) mask는 (N,512,512,1) 이 될 것임.\n",
    "# image 파일명이 환자id_HE.png, mask는 환자id_mask.png\n",
    "\n",
    "def load_data(npy_path):\n",
    "    print('-'*30)\n",
    "    print('load images...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    for i, path in enumerate(npy_path):\n",
    "#         print(path)\n",
    "        mask_npy_path = path.replace('_HE','_mask')\n",
    "        train_npy_path = path\n",
    "    \n",
    "        imgs_tmp = [cv2.imread(train_npy_path)]\n",
    "        imgs_mask_tmp = [cv2.imread(mask_npy_path,0)]\n",
    "#         print(imgs_tmp.shape, imgs_mask_tmp.shape)\n",
    "        \n",
    "        if i==0:\n",
    "            imgs = imgs_tmp\n",
    "            imgs_mask = imgs_mask_tmp\n",
    "            \n",
    "        else:\n",
    "            imgs = np.append(imgs, imgs_tmp,axis=0)\n",
    "            imgs_mask = np.append(imgs_mask, imgs_mask_tmp,axis=0)\n",
    "    imgs_tmp,imgs_mask_tmp = 0,0\n",
    "    print('-'*30)\n",
    "    print('imgs : {} \\nmasks : {}'.format(imgs.shape, imgs_mask.shape))    \n",
    "    print('-'*30)\n",
    "    imgs = imgs.astype('float32')\n",
    "    imgs_mask = imgs_mask.astype('float32')\n",
    "    print('img : ', imgs.max())\n",
    "    print('mask : ',imgs_mask.max())\n",
    "\n",
    "    print('-'*30)\n",
    "    print('normalization start...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs = cv2.normalize(imgs, None, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    imgs_mask[imgs_mask<= 127] = 0\n",
    "    imgs_mask[imgs_mask > 127] = 1\n",
    "\n",
    "    print('img : ',imgs.max())\n",
    "    print('mask : ',imgs_mask.max())\n",
    "\n",
    "    return imgs, imgs_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:48.261578Z",
     "start_time": "2022-01-24T01:42:48.225789Z"
    }
   },
   "outputs": [],
   "source": [
    "#지정된 경로의 folder가 없으면 생성해주는 함수.\n",
    "\n",
    "def mkfolder(folder):\n",
    "    if not os.path.lexists(folder):\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:48.451019Z",
     "start_time": "2022-01-24T01:42:48.439717Z"
    }
   },
   "outputs": [],
   "source": [
    "#모델 metric으로 사용될 recall을 정의해주는 함수\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_true_yn = K.round(K.clip(y_true, 0, 1)) # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1)) # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_true_yn * y_pred_yn) \n",
    "\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_true_yn)\n",
    "\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "\n",
    "    # return a single tensor value\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:42:49.297436Z",
     "start_time": "2022-01-24T01:42:49.288213Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = '../../1. 데이터/4. 골반 분할 연구 데이터/'\n",
    "all_patient = np.array([i.replace('_HE.png', '') for i in os.listdir(img_path) if '_HE.png' in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000000', '100000', '1002', '1003', '1004', '1005', '1006',\n",
       "       '1007', '1008', '1009', '100', '1010', '1012', '1013', '1014',\n",
       "       '1015', '1016', '1018', '101', '1020000', '1022', '1024', '1025',\n",
       "       '1026', '1028', '1029', '102', '1031', '1032', '1033', '1035',\n",
       "       '1036', '1037', '1039', '103', '1040000', '1040', '1043', '1044',\n",
       "       '1045', '1046', '1047', '1048', '1049', '104', '1050000', '1056',\n",
       "       '1058', '1059', '105', '1060000', '1060', '1061', '1062', '1063',\n",
       "       '1065', '1066', '1067', '1068', '1069', '106', '1070000', '1071',\n",
       "       '1072', '1073', '1074', '1075', '1076', '1078', '1079', '107',\n",
       "       '1080000', '1081', '1082', '1083', '1084', '1085', '1086', '1087',\n",
       "       '1088', '1089', '108', '10900000', '1090000', '1091', '1096',\n",
       "       '1097', '1098', '1099', '109', '10', '1100000', '110000', '1100',\n",
       "       '1102', '1103', '1104', '1105', '1106', '1107', '1109', '110',\n",
       "       '1111', '1112', '1114', '1115', '1116', '1117', '111', '1122',\n",
       "       '1123', '1124', '1125', '1126', '1127', '1128', '1129', '112',\n",
       "       '1130', '1131'], dtype='<U8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T05:57:17.113364Z",
     "start_time": "2022-01-24T05:57:17.095258Z"
    }
   },
   "outputs": [],
   "source": [
    "#5-fold cross validation을 하기 위해서 불러온 환자리스트를 나누어줌\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=5, shuffle=True)\n",
    "fold = []\n",
    "for train_index, test_index in kf.split(all_patient):\n",
    "    train_patient, test_patient = all_patient[train_index.astype(int)], all_patient[test_index.astype(int)]    \n",
    "    \n",
    "    testset = [img_path+'{}_HE.png'.format(p) for p in test_patient]\n",
    "    trainset = [img_path+'{}_HE.png'.format(p) for p in train_patient]\n",
    "\n",
    "    fold.append([trainset, testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['../../1. 데이터/4. 골반 분할 연구 데이터/1000000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1002_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1003_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1004_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1005_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1007_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1008_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1009_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1010_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1012_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1013_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1014_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1015_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1016_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/101_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1020000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1024_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1025_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1028_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1029_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1031_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1033_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1035_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1036_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1037_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1039_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1043_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1044_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1046_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1047_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1050000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1056_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1058_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1059_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1061_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1062_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1063_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1065_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1068_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1070000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1071_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1073_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1074_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1076_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1078_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1079_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1081_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1082_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1084_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1085_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1086_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1087_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1089_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/108_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10900000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1090000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1091_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1096_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1097_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1099_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1114_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1115_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1116_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1117_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1122_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1124_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1125_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1126_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1127_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1128_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1129_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1130_HE.png'],\n",
       "  ['../../1. 데이터/4. 골반 분할 연구 데이터/1006_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1018_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1022_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1026_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1032_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1045_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1048_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1049_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1066_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1067_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1069_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1072_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1075_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1080000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1083_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1088_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1098_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1123_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1131_HE.png']],\n",
       " [['../../1. 데이터/4. 골반 분할 연구 데이터/1000000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1002_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1003_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1004_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1005_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1006_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1007_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1008_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1009_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1010_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1014_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1015_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1016_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1018_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/101_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1020000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1022_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1024_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1026_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1029_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1031_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1032_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1033_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1035_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1036_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1039_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1044_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1045_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1047_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1048_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1049_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1058_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1062_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1065_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1066_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1067_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1068_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1069_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1070000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1071_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1072_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1074_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1075_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1076_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1078_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1079_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1080000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1081_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1082_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1083_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1084_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1085_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1086_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1087_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1088_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1089_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10900000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1091_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1096_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1097_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1098_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1099_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1114_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1115_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1116_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1117_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1122_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1123_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1124_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1126_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1127_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1129_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1130_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1131_HE.png'],\n",
       "  ['../../1. 데이터/4. 골반 분할 연구 데이터/1012_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1013_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1025_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1028_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1037_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1043_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1046_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1050000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1056_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1059_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1061_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1063_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1073_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/108_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1090000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1125_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1128_HE.png']],\n",
       " [['../../1. 데이터/4. 골반 분할 연구 데이터/1000000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1002_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1004_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1005_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1006_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1007_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1008_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1009_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1012_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1013_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1015_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1016_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1018_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/101_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1022_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1025_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1026_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1028_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1031_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1032_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1035_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1036_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1037_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1043_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1044_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1045_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1046_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1047_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1048_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1049_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1050000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1056_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1058_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1059_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1061_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1062_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1063_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1066_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1067_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1068_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1069_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1070000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1071_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1072_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1073_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1074_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1075_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1078_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1080000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1082_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1083_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1084_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1085_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1086_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1087_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1088_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1089_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/108_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10900000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1090000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1091_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1097_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1098_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1116_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1117_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1122_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1123_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1124_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1125_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1127_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1128_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1130_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1131_HE.png'],\n",
       "  ['../../1. 데이터/4. 골반 분할 연구 데이터/1003_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1010_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1014_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1020000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1024_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1029_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1033_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1039_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1065_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1076_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1079_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1081_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1096_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1099_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1114_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1115_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1126_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1129_HE.png']],\n",
       " [['../../1. 데이터/4. 골반 분할 연구 데이터/1003_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1006_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1007_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1008_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1010_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1012_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1013_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1014_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1015_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1016_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1018_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1020000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1022_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1024_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1025_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1026_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1028_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1029_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1031_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1032_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1033_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1035_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1037_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1039_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1043_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1045_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1046_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1048_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1049_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1050000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1056_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1059_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1061_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1062_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1063_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1065_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1066_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1067_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1069_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1070000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1071_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1072_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1073_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1074_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1075_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1076_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1079_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1080000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1081_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1082_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1083_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1084_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1085_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1086_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1087_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1088_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1089_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/108_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1090000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1096_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1098_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1099_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1114_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1115_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1116_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1123_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1124_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1125_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1126_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1128_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1129_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1131_HE.png'],\n",
       "  ['../../1. 데이터/4. 골반 분할 연구 데이터/1000000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1002_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1004_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1005_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1009_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/101_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1036_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1044_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1047_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1058_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1068_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1078_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10900000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1091_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1097_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1117_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1122_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1127_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1130_HE.png']],\n",
       " [['../../1. 데이터/4. 골반 분할 연구 데이터/1000000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1002_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1003_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1004_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1005_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1006_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1009_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1010_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1012_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1013_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1014_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1018_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/101_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1020000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1022_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1024_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1025_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1026_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1028_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1029_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1032_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1033_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1036_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1037_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1039_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1040_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1043_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1044_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1045_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1046_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1047_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1048_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1049_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1050000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1056_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1058_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1059_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1060_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1061_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1063_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1065_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1066_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1067_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1068_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1069_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1072_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1073_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1075_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1076_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1078_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1079_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1080000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1081_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1083_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1088_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/108_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10900000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1090000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1091_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1096_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1097_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1098_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1099_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/10_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1100_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1102_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1103_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1105_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1106_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/110_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1114_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1115_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1117_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1122_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1123_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1125_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1126_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1127_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1128_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1129_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1130_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1131_HE.png'],\n",
       "  ['../../1. 데이터/4. 골반 분할 연구 데이터/1007_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1008_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1015_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1016_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1031_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1035_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/104_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1062_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1070000_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1071_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1074_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1082_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1084_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1085_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1086_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1087_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1089_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1107_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1109_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1112_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1116_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/111_HE.png',\n",
       "   '../../1. 데이터/4. 골반 분할 연구 데이터/1124_HE.png']]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data 증강을 위해서 이미지 변형의 범위를 지정해주는 부분\n",
    "#rotation_range 범위 내의 각도만큼 돌아가는 이미지를 생성하고\n",
    "#width/height shift만큼 위치가 이동된 이미지를 생성하고\n",
    "#zoom_range 범위만큼 확대/축소된 이미지를 생성하고\n",
    "#horizontal_flip이 있으니까 좌우 반전된 이미지도 생성함\n",
    "\n",
    "data_gen_args = dict(rotation_range=10.,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    zoom_range=0.2, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T05:57:24.532325Z",
     "start_time": "2022-01-24T05:57:24.523232Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (96, 512, 512, 3) \n",
      "masks : (96, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 22:38:28.331596: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 22:38:29.611980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22325 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:3b:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "start training\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 22:38:32.303197: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 22:38:37.827000: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008/3008 [==============================] - 226s 69ms/step - loss: 0.1476 - acc: 0.9100 - binary_crossentropy: 0.4420 - recall: 0.9070 - val_loss: 0.1999 - val_acc: 0.8708 - val_binary_crossentropy: 1.0479 - val_recall: 0.9646\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19988, saving model to 6_result/exp_fold0/model/best.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/anaconda3/envs/JM_lee/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "3008/3008 [==============================] - 206s 68ms/step - loss: 0.0680 - acc: 0.9560 - binary_crossentropy: 0.2725 - recall: 0.9444 - val_loss: 0.2946 - val_acc: 0.8647 - val_binary_crossentropy: 1.2634 - val_recall: 0.6421\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19988\n",
      "Epoch 3/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0480 - acc: 0.9671 - binary_crossentropy: 0.2203 - recall: 0.9584 - val_loss: 0.1834 - val_acc: 0.8960 - val_binary_crossentropy: 1.0741 - val_recall: 0.8761\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.19988 to 0.18341, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 4/100\n",
      "3008/3008 [==============================] - 203s 68ms/step - loss: 0.0370 - acc: 0.9729 - binary_crossentropy: 0.1903 - recall: 0.9665 - val_loss: 0.1833 - val_acc: 0.8866 - val_binary_crossentropy: 1.4327 - val_recall: 0.9426\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.18341 to 0.18330, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 5/100\n",
      "3008/3008 [==============================] - 207s 69ms/step - loss: 0.0306 - acc: 0.9766 - binary_crossentropy: 0.1746 - recall: 0.9717 - val_loss: 0.1820 - val_acc: 0.8924 - val_binary_crossentropy: 1.4539 - val_recall: 0.9130\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.18330 to 0.18201, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 6/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0273 - acc: 0.9785 - binary_crossentropy: 0.1687 - recall: 0.9745 - val_loss: 0.1825 - val_acc: 0.9027 - val_binary_crossentropy: 1.3523 - val_recall: 0.8358\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.18201\n",
      "Epoch 7/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0246 - acc: 0.9798 - binary_crossentropy: 0.1644 - recall: 0.9769 - val_loss: 0.2047 - val_acc: 0.8904 - val_binary_crossentropy: 1.6677 - val_recall: 0.8161\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.18201\n",
      "Epoch 8/100\n",
      "3008/3008 [==============================] - 203s 68ms/step - loss: 0.0229 - acc: 0.9807 - binary_crossentropy: 0.1637 - recall: 0.9785 - val_loss: 0.1846 - val_acc: 0.9021 - val_binary_crossentropy: 1.5618 - val_recall: 0.8260\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18201\n",
      "Epoch 9/100\n",
      "3008/3008 [==============================] - 187s 62ms/step - loss: 0.0213 - acc: 0.9816 - binary_crossentropy: 0.1591 - recall: 0.9800 - val_loss: 0.2257 - val_acc: 0.8911 - val_binary_crossentropy: 1.9699 - val_recall: 0.7283\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18201\n",
      "Epoch 10/100\n",
      "3008/3008 [==============================] - 162s 54ms/step - loss: 0.0201 - acc: 0.9823 - binary_crossentropy: 0.1581 - recall: 0.9811 - val_loss: 0.1946 - val_acc: 0.8984 - val_binary_crossentropy: 1.7997 - val_recall: 0.8126\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18201\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 11/100\n",
      "3008/3008 [==============================] - 195s 65ms/step - loss: 0.0162 - acc: 0.9844 - binary_crossentropy: 0.1328 - recall: 0.9849 - val_loss: 0.1882 - val_acc: 0.9025 - val_binary_crossentropy: 1.7659 - val_recall: 0.8119\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.18201\n",
      "Epoch 12/100\n",
      "3008/3008 [==============================] - 198s 66ms/step - loss: 0.0155 - acc: 0.9849 - binary_crossentropy: 0.1290 - recall: 0.9857 - val_loss: 0.1946 - val_acc: 0.9026 - val_binary_crossentropy: 1.8314 - val_recall: 0.7835\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18201\n",
      "Epoch 13/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0151 - acc: 0.9851 - binary_crossentropy: 0.1291 - recall: 0.9860 - val_loss: 0.1819 - val_acc: 0.9043 - val_binary_crossentropy: 1.8120 - val_recall: 0.8230\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.18201 to 0.18187, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 14/100\n",
      "3008/3008 [==============================] - 204s 68ms/step - loss: 0.0149 - acc: 0.9852 - binary_crossentropy: 0.1300 - recall: 0.9862 - val_loss: 0.1809 - val_acc: 0.9051 - val_binary_crossentropy: 1.7956 - val_recall: 0.8290\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18187 to 0.18086, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 15/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0147 - acc: 0.9853 - binary_crossentropy: 0.1289 - recall: 0.9865 - val_loss: 0.1871 - val_acc: 0.9016 - val_binary_crossentropy: 1.8859 - val_recall: 0.8168\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18086\n",
      "Epoch 16/100\n",
      "3008/3008 [==============================] - 194s 65ms/step - loss: 0.0145 - acc: 0.9854 - binary_crossentropy: 0.1297 - recall: 0.9866 - val_loss: 0.2034 - val_acc: 0.8956 - val_binary_crossentropy: 2.0601 - val_recall: 0.7872\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.18086\n",
      "Epoch 17/100\n",
      "3008/3008 [==============================] - 193s 64ms/step - loss: 0.0144 - acc: 0.9855 - binary_crossentropy: 0.1289 - recall: 0.9868 - val_loss: 0.1807 - val_acc: 0.9056 - val_binary_crossentropy: 1.8356 - val_recall: 0.8235\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.18086 to 0.18071, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 18/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0142 - acc: 0.9855 - binary_crossentropy: 0.1279 - recall: 0.9870 - val_loss: 0.1889 - val_acc: 0.9022 - val_binary_crossentropy: 1.9302 - val_recall: 0.8079\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.18071\n",
      "Epoch 19/100\n",
      "3008/3008 [==============================] - 174s 58ms/step - loss: 0.0141 - acc: 0.9856 - binary_crossentropy: 0.1283 - recall: 0.9871 - val_loss: 0.1863 - val_acc: 0.9047 - val_binary_crossentropy: 1.8818 - val_recall: 0.8011\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18071\n",
      "Epoch 20/100\n",
      "3008/3008 [==============================] - 192s 64ms/step - loss: 0.0139 - acc: 0.9857 - binary_crossentropy: 0.1264 - recall: 0.9872 - val_loss: 0.1918 - val_acc: 0.9004 - val_binary_crossentropy: 1.9793 - val_recall: 0.8075\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.18071\n",
      "Epoch 21/100\n",
      "3008/3008 [==============================] - 163s 54ms/step - loss: 0.0138 - acc: 0.9857 - binary_crossentropy: 0.1268 - recall: 0.9873 - val_loss: 0.1871 - val_acc: 0.9026 - val_binary_crossentropy: 1.9480 - val_recall: 0.8141\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.18071\n",
      "Epoch 22/100\n",
      "3008/3008 [==============================] - 161s 54ms/step - loss: 0.0136 - acc: 0.9857 - binary_crossentropy: 0.1269 - recall: 0.9875 - val_loss: 0.1949 - val_acc: 0.8976 - val_binary_crossentropy: 2.0873 - val_recall: 0.8100\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.18071\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 23/100\n",
      "3008/3008 [==============================] - 177s 59ms/step - loss: 0.0134 - acc: 0.9859 - binary_crossentropy: 0.1240 - recall: 0.9878 - val_loss: 0.1811 - val_acc: 0.9046 - val_binary_crossentropy: 1.9315 - val_recall: 0.8243\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.18071\n",
      "Epoch 24/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0133 - acc: 0.9859 - binary_crossentropy: 0.1239 - recall: 0.9878 - val_loss: 0.1890 - val_acc: 0.9018 - val_binary_crossentropy: 1.9786 - val_recall: 0.8147\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.18071\n",
      "Epoch 25/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0134 - acc: 0.9860 - binary_crossentropy: 0.1238 - recall: 0.9878 - val_loss: 0.1793 - val_acc: 0.9050 - val_binary_crossentropy: 1.9294 - val_recall: 0.8311\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.18071 to 0.17929, saving model to 6_result/exp_fold0/model/best.h5\n",
      "Epoch 26/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0133 - acc: 0.9860 - binary_crossentropy: 0.1238 - recall: 0.9879 - val_loss: 0.1878 - val_acc: 0.9016 - val_binary_crossentropy: 2.0105 - val_recall: 0.8191\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.17929\n",
      "Epoch 27/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0133 - acc: 0.9860 - binary_crossentropy: 0.1234 - recall: 0.9880 - val_loss: 0.1855 - val_acc: 0.9026 - val_binary_crossentropy: 1.9845 - val_recall: 0.8200\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.17929\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008/3008 [==============================] - 174s 58ms/step - loss: 0.0132 - acc: 0.9860 - binary_crossentropy: 0.1230 - recall: 0.9880 - val_loss: 0.1875 - val_acc: 0.9023 - val_binary_crossentropy: 2.0069 - val_recall: 0.8134\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.17929\n",
      "Epoch 29/100\n",
      "3008/3008 [==============================] - 182s 61ms/step - loss: 0.0132 - acc: 0.9861 - binary_crossentropy: 0.1227 - recall: 0.9880 - val_loss: 0.1844 - val_acc: 0.9031 - val_binary_crossentropy: 1.9814 - val_recall: 0.8242\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.17929\n",
      "Epoch 30/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0132 - acc: 0.9861 - binary_crossentropy: 0.1223 - recall: 0.9881 - val_loss: 0.1839 - val_acc: 0.9038 - val_binary_crossentropy: 1.9963 - val_recall: 0.8192\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17929\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 31/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1224 - recall: 0.9881 - val_loss: 0.1863 - val_acc: 0.9024 - val_binary_crossentropy: 2.0113 - val_recall: 0.8197\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.17929\n",
      "Epoch 32/100\n",
      "3008/3008 [==============================] - 193s 64ms/step - loss: 0.0133 - acc: 0.9860 - binary_crossentropy: 0.1237 - recall: 0.9879 - val_loss: 0.1827 - val_acc: 0.9044 - val_binary_crossentropy: 1.9686 - val_recall: 0.8218\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.17929\n",
      "Epoch 33/100\n",
      "3008/3008 [==============================] - 173s 58ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1219 - recall: 0.9881 - val_loss: 0.1828 - val_acc: 0.9032 - val_binary_crossentropy: 1.9715 - val_recall: 0.8281\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.17929\n",
      "Epoch 34/100\n",
      "3008/3008 [==============================] - 180s 60ms/step - loss: 0.0132 - acc: 0.9859 - binary_crossentropy: 0.1238 - recall: 0.9880 - val_loss: 0.1839 - val_acc: 0.9037 - val_binary_crossentropy: 1.9660 - val_recall: 0.8218\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.17929\n",
      "Epoch 35/100\n",
      "3008/3008 [==============================] - 194s 65ms/step - loss: 0.0132 - acc: 0.9860 - binary_crossentropy: 0.1236 - recall: 0.9880 - val_loss: 0.1849 - val_acc: 0.9028 - val_binary_crossentropy: 1.9907 - val_recall: 0.8232\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.17929\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 36/100\n",
      "3008/3008 [==============================] - 197s 65ms/step - loss: 0.0132 - acc: 0.9860 - binary_crossentropy: 0.1229 - recall: 0.9881 - val_loss: 0.1873 - val_acc: 0.9020 - val_binary_crossentropy: 2.0007 - val_recall: 0.8177\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.17929\n",
      "Epoch 37/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1224 - recall: 0.9881 - val_loss: 0.1853 - val_acc: 0.9028 - val_binary_crossentropy: 1.9767 - val_recall: 0.8203\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.17929\n",
      "Epoch 38/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0132 - acc: 0.9860 - binary_crossentropy: 0.1231 - recall: 0.9880 - val_loss: 0.1858 - val_acc: 0.9026 - val_binary_crossentropy: 1.9872 - val_recall: 0.8199\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.17929\n",
      "Epoch 39/100\n",
      "3008/3008 [==============================] - 207s 69ms/step - loss: 0.0132 - acc: 0.9861 - binary_crossentropy: 0.1220 - recall: 0.9881 - val_loss: 0.1806 - val_acc: 0.9052 - val_binary_crossentropy: 1.9450 - val_recall: 0.8256\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.17929\n",
      "Epoch 40/100\n",
      "3008/3008 [==============================] - 197s 65ms/step - loss: 0.0132 - acc: 0.9861 - binary_crossentropy: 0.1222 - recall: 0.9881 - val_loss: 0.1887 - val_acc: 0.9010 - val_binary_crossentropy: 2.0205 - val_recall: 0.8145\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.17929\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 41/100\n",
      "3008/3008 [==============================] - 192s 64ms/step - loss: 0.0131 - acc: 0.9862 - binary_crossentropy: 0.1213 - recall: 0.9882 - val_loss: 0.1835 - val_acc: 0.9037 - val_binary_crossentropy: 1.9768 - val_recall: 0.8248\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.17929\n",
      "Epoch 42/100\n",
      "3008/3008 [==============================] - 193s 64ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1223 - recall: 0.9881 - val_loss: 0.1850 - val_acc: 0.9023 - val_binary_crossentropy: 2.0042 - val_recall: 0.8226\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.17929\n",
      "Epoch 43/100\n",
      "3008/3008 [==============================] - 194s 64ms/step - loss: 0.0131 - acc: 0.9862 - binary_crossentropy: 0.1214 - recall: 0.9881 - val_loss: 0.1822 - val_acc: 0.9042 - val_binary_crossentropy: 1.9658 - val_recall: 0.8259\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17929\n",
      "Epoch 44/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0131 - acc: 0.9860 - binary_crossentropy: 0.1229 - recall: 0.9880 - val_loss: 0.1839 - val_acc: 0.9027 - val_binary_crossentropy: 1.9882 - val_recall: 0.8279\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.17929\n",
      "Epoch 45/100\n",
      "3008/3008 [==============================] - 204s 68ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1215 - recall: 0.9881 - val_loss: 0.1870 - val_acc: 0.9021 - val_binary_crossentropy: 2.0094 - val_recall: 0.8170\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.17929\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 00045: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (96, 512, 512, 3) \n",
      "masks : (96, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "3008/3008 [==============================] - 206s 68ms/step - loss: 0.1409 - acc: 0.9164 - binary_crossentropy: 0.3449 - recall: 0.9052 - val_loss: 0.8030 - val_acc: 0.7501 - val_binary_crossentropy: 2.0287 - val_recall: 0.1418\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.80295, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 2/100\n",
      "3008/3008 [==============================] - 198s 66ms/step - loss: 0.0660 - acc: 0.9576 - binary_crossentropy: 0.2395 - recall: 0.9449 - val_loss: 0.1796 - val_acc: 0.8963 - val_binary_crossentropy: 0.8973 - val_recall: 0.9084\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.80295 to 0.17958, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 3/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0456 - acc: 0.9686 - binary_crossentropy: 0.1993 - recall: 0.9606 - val_loss: 0.2968 - val_acc: 0.8583 - val_binary_crossentropy: 1.7749 - val_recall: 0.6737\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.17958\n",
      "Epoch 4/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0354 - acc: 0.9739 - binary_crossentropy: 0.1810 - recall: 0.9685 - val_loss: 0.1783 - val_acc: 0.9139 - val_binary_crossentropy: 1.1117 - val_recall: 0.7983\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.17958 to 0.17834, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 5/100\n",
      "3008/3008 [==============================] - 195s 65ms/step - loss: 0.0295 - acc: 0.9774 - binary_crossentropy: 0.1685 - recall: 0.9731 - val_loss: 0.2338 - val_acc: 0.8853 - val_binary_crossentropy: 1.7499 - val_recall: 0.7348\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17834\n",
      "Epoch 6/100\n",
      "3008/3008 [==============================] - 194s 64ms/step - loss: 0.0262 - acc: 0.9791 - binary_crossentropy: 0.1649 - recall: 0.9760 - val_loss: 0.1637 - val_acc: 0.9046 - val_binary_crossentropy: 1.3273 - val_recall: 0.9231\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.17834 to 0.16372, saving model to 6_result/exp_fold1/model/best.h5\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008/3008 [==============================] - 194s 64ms/step - loss: 0.0235 - acc: 0.9805 - binary_crossentropy: 0.1601 - recall: 0.9783 - val_loss: 0.1788 - val_acc: 0.9015 - val_binary_crossentropy: 1.5421 - val_recall: 0.8675\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16372\n",
      "Epoch 8/100\n",
      "3008/3008 [==============================] - 211s 70ms/step - loss: 0.0222 - acc: 0.9811 - binary_crossentropy: 0.1625 - recall: 0.9794 - val_loss: 0.2719 - val_acc: 0.8745 - val_binary_crossentropy: 2.4487 - val_recall: 0.6653\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16372\n",
      "Epoch 9/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0203 - acc: 0.9823 - binary_crossentropy: 0.1558 - recall: 0.9812 - val_loss: 0.1853 - val_acc: 0.8959 - val_binary_crossentropy: 1.7754 - val_recall: 0.8773\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16372\n",
      "Epoch 10/100\n",
      "3008/3008 [==============================] - 194s 65ms/step - loss: 0.0202 - acc: 0.9823 - binary_crossentropy: 0.1539 - recall: 0.9813 - val_loss: 0.2012 - val_acc: 0.8992 - val_binary_crossentropy: 1.6964 - val_recall: 0.7858\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16372\n",
      "Epoch 11/100\n",
      "3008/3008 [==============================] - 193s 64ms/step - loss: 0.0182 - acc: 0.9833 - binary_crossentropy: 0.1438 - recall: 0.9832 - val_loss: 0.3204 - val_acc: 0.8639 - val_binary_crossentropy: 3.3998 - val_recall: 0.5783\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16372\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 12/100\n",
      "3008/3008 [==============================] - 206s 68ms/step - loss: 0.0152 - acc: 0.9851 - binary_crossentropy: 0.1290 - recall: 0.9861 - val_loss: 0.1954 - val_acc: 0.8945 - val_binary_crossentropy: 1.9365 - val_recall: 0.8397\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16372\n",
      "Epoch 13/100\n",
      "3008/3008 [==============================] - 203s 67ms/step - loss: 0.0145 - acc: 0.9854 - binary_crossentropy: 0.1284 - recall: 0.9867 - val_loss: 0.1839 - val_acc: 0.9006 - val_binary_crossentropy: 1.8309 - val_recall: 0.8546\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16372\n",
      "Epoch 14/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0143 - acc: 0.9856 - binary_crossentropy: 0.1282 - recall: 0.9870 - val_loss: 0.1828 - val_acc: 0.9048 - val_binary_crossentropy: 1.8328 - val_recall: 0.8354\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16372\n",
      "Epoch 15/100\n",
      "3008/3008 [==============================] - 197s 66ms/step - loss: 0.0140 - acc: 0.9857 - binary_crossentropy: 0.1279 - recall: 0.9872 - val_loss: 0.1868 - val_acc: 0.9017 - val_binary_crossentropy: 1.9246 - val_recall: 0.8364\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16372\n",
      "Epoch 16/100\n",
      "3008/3008 [==============================] - 192s 64ms/step - loss: 0.0139 - acc: 0.9857 - binary_crossentropy: 0.1268 - recall: 0.9874 - val_loss: 0.2005 - val_acc: 0.8965 - val_binary_crossentropy: 2.1602 - val_recall: 0.8066\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16372\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 17/100\n",
      "3008/3008 [==============================] - 192s 64ms/step - loss: 0.0136 - acc: 0.9859 - binary_crossentropy: 0.1248 - recall: 0.9876 - val_loss: 0.1882 - val_acc: 0.8999 - val_binary_crossentropy: 1.9670 - val_recall: 0.8377\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16372\n",
      "Epoch 18/100\n",
      "3008/3008 [==============================] - 191s 64ms/step - loss: 0.0136 - acc: 0.9858 - binary_crossentropy: 0.1252 - recall: 0.9876 - val_loss: 0.1875 - val_acc: 0.9003 - val_binary_crossentropy: 1.9565 - val_recall: 0.8401\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16372\n",
      "Epoch 19/100\n",
      "3008/3008 [==============================] - 194s 64ms/step - loss: 0.0136 - acc: 0.9858 - binary_crossentropy: 0.1253 - recall: 0.9876 - val_loss: 0.1893 - val_acc: 0.8991 - val_binary_crossentropy: 1.9710 - val_recall: 0.8385\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16372\n",
      "Epoch 20/100\n",
      "3008/3008 [==============================] - 193s 64ms/step - loss: 0.0135 - acc: 0.9860 - binary_crossentropy: 0.1236 - recall: 0.9878 - val_loss: 0.1889 - val_acc: 0.8992 - val_binary_crossentropy: 1.9833 - val_recall: 0.8372\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16372\n",
      "Epoch 21/100\n",
      "3008/3008 [==============================] - 187s 62ms/step - loss: 0.0134 - acc: 0.9860 - binary_crossentropy: 0.1235 - recall: 0.9878 - val_loss: 0.1890 - val_acc: 0.8992 - val_binary_crossentropy: 1.9824 - val_recall: 0.8395\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16372\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 22/100\n",
      "3008/3008 [==============================] - 198s 66ms/step - loss: 0.0135 - acc: 0.9859 - binary_crossentropy: 0.1242 - recall: 0.9878 - val_loss: 0.1864 - val_acc: 0.9009 - val_binary_crossentropy: 1.9433 - val_recall: 0.8414\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16372\n",
      "Epoch 23/100\n",
      "3008/3008 [==============================] - 196s 65ms/step - loss: 0.0134 - acc: 0.9859 - binary_crossentropy: 0.1241 - recall: 0.9877 - val_loss: 0.1835 - val_acc: 0.9021 - val_binary_crossentropy: 1.9171 - val_recall: 0.8472\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16372\n",
      "Epoch 24/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0134 - acc: 0.9859 - binary_crossentropy: 0.1238 - recall: 0.9878 - val_loss: 0.1877 - val_acc: 0.9008 - val_binary_crossentropy: 1.9571 - val_recall: 0.8356\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16372\n",
      "Epoch 25/100\n",
      "3008/3008 [==============================] - 203s 67ms/step - loss: 0.0135 - acc: 0.9860 - binary_crossentropy: 0.1235 - recall: 0.9878 - val_loss: 0.1887 - val_acc: 0.8999 - val_binary_crossentropy: 1.9759 - val_recall: 0.8393\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.16372\n",
      "Epoch 26/100\n",
      "3008/3008 [==============================] - 206s 68ms/step - loss: 0.0134 - acc: 0.9860 - binary_crossentropy: 0.1235 - recall: 0.9878 - val_loss: 0.1887 - val_acc: 0.8993 - val_binary_crossentropy: 1.9857 - val_recall: 0.8406\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.16372\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 00026: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (96, 512, 512, 3) \n",
      "masks : (96, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "3008/3008 [==============================] - 203s 67ms/step - loss: 0.1483 - acc: 0.9078 - binary_crossentropy: 0.4768 - recall: 0.9104 - val_loss: 0.2172 - val_acc: 0.8748 - val_binary_crossentropy: 1.0052 - val_recall: 0.9262\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21719, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 2/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0679 - acc: 0.9551 - binary_crossentropy: 0.2835 - recall: 0.9453 - val_loss: 0.3404 - val_acc: 0.8540 - val_binary_crossentropy: 1.4349 - val_recall: 0.6256\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.21719\n",
      "Epoch 3/100\n",
      "3008/3008 [==============================] - 207s 69ms/step - loss: 0.0475 - acc: 0.9668 - binary_crossentropy: 0.2267 - recall: 0.9593 - val_loss: 0.2550 - val_acc: 0.8449 - val_binary_crossentropy: 1.8283 - val_recall: 0.9235\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.21719\n",
      "Epoch 4/100\n",
      "3008/3008 [==============================] - 194s 64ms/step - loss: 0.0369 - acc: 0.9724 - binary_crossentropy: 0.2005 - recall: 0.9671 - val_loss: 0.2062 - val_acc: 0.8872 - val_binary_crossentropy: 1.6142 - val_recall: 0.8960\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21719 to 0.20624, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 5/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0307 - acc: 0.9761 - binary_crossentropy: 0.1816 - recall: 0.9722 - val_loss: 0.2598 - val_acc: 0.8655 - val_binary_crossentropy: 1.8308 - val_recall: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss did not improve from 0.20624\n",
      "Epoch 6/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0271 - acc: 0.9781 - binary_crossentropy: 0.1762 - recall: 0.9750 - val_loss: 0.2313 - val_acc: 0.8801 - val_binary_crossentropy: 1.7473 - val_recall: 0.8297\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20624\n",
      "Epoch 7/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0244 - acc: 0.9795 - binary_crossentropy: 0.1692 - recall: 0.9775 - val_loss: 0.2025 - val_acc: 0.8940 - val_binary_crossentropy: 1.5134 - val_recall: 0.8655\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20624 to 0.20247, saving model to 6_result/exp_fold2/model/best.h5\n",
      "Epoch 8/100\n",
      "3008/3008 [==============================] - 207s 69ms/step - loss: 0.0225 - acc: 0.9805 - binary_crossentropy: 0.1670 - recall: 0.9791 - val_loss: 0.3219 - val_acc: 0.8494 - val_binary_crossentropy: 2.5631 - val_recall: 0.6898\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20247\n",
      "Epoch 9/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0208 - acc: 0.9816 - binary_crossentropy: 0.1598 - recall: 0.9807 - val_loss: 0.3254 - val_acc: 0.8663 - val_binary_crossentropy: 2.3873 - val_recall: 0.6135\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20247\n",
      "Epoch 10/100\n",
      "3008/3008 [==============================] - 204s 68ms/step - loss: 0.0196 - acc: 0.9822 - binary_crossentropy: 0.1575 - recall: 0.9818 - val_loss: 0.3442 - val_acc: 0.8573 - val_binary_crossentropy: 2.8043 - val_recall: 0.6068\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20247\n",
      "Epoch 11/100\n",
      "3008/3008 [==============================] - 214s 71ms/step - loss: 0.0186 - acc: 0.9828 - binary_crossentropy: 0.1547 - recall: 0.9828 - val_loss: 0.2891 - val_acc: 0.8502 - val_binary_crossentropy: 3.0812 - val_recall: 0.7880\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20247\n",
      "Epoch 12/100\n",
      "3008/3008 [==============================] - 216s 72ms/step - loss: 0.0177 - acc: 0.9833 - binary_crossentropy: 0.1538 - recall: 0.9836 - val_loss: 0.3145 - val_acc: 0.8671 - val_binary_crossentropy: 2.5401 - val_recall: 0.6404\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20247\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 13/100\n",
      "3008/3008 [==============================] - 221s 73ms/step - loss: 0.0147 - acc: 0.9851 - binary_crossentropy: 0.1347 - recall: 0.9866 - val_loss: 0.2275 - val_acc: 0.8820 - val_binary_crossentropy: 2.3685 - val_recall: 0.8387\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20247\n",
      "Epoch 14/100\n",
      "3008/3008 [==============================] - 211s 70ms/step - loss: 0.0141 - acc: 0.9854 - binary_crossentropy: 0.1308 - recall: 0.9871 - val_loss: 0.2374 - val_acc: 0.8827 - val_binary_crossentropy: 2.3618 - val_recall: 0.8001\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20247\n",
      "Epoch 15/100\n",
      "3008/3008 [==============================] - 207s 69ms/step - loss: 0.0139 - acc: 0.9855 - binary_crossentropy: 0.1293 - recall: 0.9872 - val_loss: 0.2359 - val_acc: 0.8795 - val_binary_crossentropy: 2.4146 - val_recall: 0.8226\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20247\n",
      "Epoch 16/100\n",
      "3008/3008 [==============================] - 191s 63ms/step - loss: 0.0138 - acc: 0.9855 - binary_crossentropy: 0.1299 - recall: 0.9874 - val_loss: 0.2269 - val_acc: 0.8808 - val_binary_crossentropy: 2.3961 - val_recall: 0.8445\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20247\n",
      "Epoch 17/100\n",
      "3008/3008 [==============================] - 214s 71ms/step - loss: 0.0135 - acc: 0.9857 - binary_crossentropy: 0.1286 - recall: 0.9877 - val_loss: 0.2247 - val_acc: 0.8828 - val_binary_crossentropy: 2.4056 - val_recall: 0.8460\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.20247\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 18/100\n",
      "3008/3008 [==============================] - 213s 71ms/step - loss: 0.0133 - acc: 0.9858 - binary_crossentropy: 0.1268 - recall: 0.9879 - val_loss: 0.2261 - val_acc: 0.8831 - val_binary_crossentropy: 2.4306 - val_recall: 0.8391\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.20247\n",
      "Epoch 19/100\n",
      "3008/3008 [==============================] - 206s 69ms/step - loss: 0.0133 - acc: 0.9857 - binary_crossentropy: 0.1269 - recall: 0.9879 - val_loss: 0.2299 - val_acc: 0.8816 - val_binary_crossentropy: 2.4308 - val_recall: 0.8318\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.20247\n",
      "Epoch 20/100\n",
      "3008/3008 [==============================] - 188s 63ms/step - loss: 0.0133 - acc: 0.9858 - binary_crossentropy: 0.1260 - recall: 0.9879 - val_loss: 0.2271 - val_acc: 0.8833 - val_binary_crossentropy: 2.4162 - val_recall: 0.8344\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.20247\n",
      "Epoch 21/100\n",
      "3008/3008 [==============================] - 192s 64ms/step - loss: 0.0132 - acc: 0.9858 - binary_crossentropy: 0.1258 - recall: 0.9880 - val_loss: 0.2275 - val_acc: 0.8826 - val_binary_crossentropy: 2.4246 - val_recall: 0.8341\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.20247\n",
      "Epoch 22/100\n",
      "3008/3008 [==============================] - 196s 65ms/step - loss: 0.0131 - acc: 0.9859 - binary_crossentropy: 0.1247 - recall: 0.9882 - val_loss: 0.2268 - val_acc: 0.8836 - val_binary_crossentropy: 2.4028 - val_recall: 0.8337\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.20247\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 23/100\n",
      "3008/3008 [==============================] - 193s 64ms/step - loss: 0.0130 - acc: 0.9859 - binary_crossentropy: 0.1244 - recall: 0.9882 - val_loss: 0.2280 - val_acc: 0.8832 - val_binary_crossentropy: 2.4116 - val_recall: 0.8307\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.20247\n",
      "Epoch 24/100\n",
      "3008/3008 [==============================] - 195s 65ms/step - loss: 0.0131 - acc: 0.9858 - binary_crossentropy: 0.1257 - recall: 0.9880 - val_loss: 0.2311 - val_acc: 0.8826 - val_binary_crossentropy: 2.4067 - val_recall: 0.8228\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20247\n",
      "Epoch 25/100\n",
      "3008/3008 [==============================] - 196s 65ms/step - loss: 0.0132 - acc: 0.9859 - binary_crossentropy: 0.1253 - recall: 0.9880 - val_loss: 0.2241 - val_acc: 0.8837 - val_binary_crossentropy: 2.4156 - val_recall: 0.8433\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20247\n",
      "Epoch 26/100\n",
      "3008/3008 [==============================] - 194s 65ms/step - loss: 0.0131 - acc: 0.9859 - binary_crossentropy: 0.1248 - recall: 0.9881 - val_loss: 0.2272 - val_acc: 0.8826 - val_binary_crossentropy: 2.4393 - val_recall: 0.8360\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20247\n",
      "Epoch 27/100\n",
      "3008/3008 [==============================] - 198s 66ms/step - loss: 0.0131 - acc: 0.9858 - binary_crossentropy: 0.1255 - recall: 0.9880 - val_loss: 0.2243 - val_acc: 0.8849 - val_binary_crossentropy: 2.3721 - val_recall: 0.8368\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20247\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 00027: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (96, 512, 512, 3) \n",
      "masks : (96, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "3008/3008 [==============================] - 198s 65ms/step - loss: 0.1413 - acc: 0.9158 - binary_crossentropy: 0.3983 - recall: 0.9104 - val_loss: 0.1969 - val_acc: 0.8988 - val_binary_crossentropy: 0.6710 - val_recall: 0.8363\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19689, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 2/100\n",
      "3008/3008 [==============================] - 195s 65ms/step - loss: 0.0626 - acc: 0.9597 - binary_crossentropy: 0.2381 - recall: 0.9475 - val_loss: 0.1971 - val_acc: 0.8855 - val_binary_crossentropy: 1.1185 - val_recall: 0.9140\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.19689\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008/3008 [==============================] - 204s 68ms/step - loss: 0.0426 - acc: 0.9704 - binary_crossentropy: 0.1907 - recall: 0.9626 - val_loss: 0.2356 - val_acc: 0.8674 - val_binary_crossentropy: 1.5961 - val_recall: 0.8599\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.19689\n",
      "Epoch 4/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0340 - acc: 0.9748 - binary_crossentropy: 0.1751 - recall: 0.9691 - val_loss: 0.1958 - val_acc: 0.9007 - val_binary_crossentropy: 1.2105 - val_recall: 0.8223\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19689 to 0.19583, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 5/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0280 - acc: 0.9783 - binary_crossentropy: 0.1585 - recall: 0.9743 - val_loss: 0.2680 - val_acc: 0.8605 - val_binary_crossentropy: 1.8930 - val_recall: 0.7733\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.19583\n",
      "Epoch 6/100\n",
      "3008/3008 [==============================] - 204s 68ms/step - loss: 0.0251 - acc: 0.9798 - binary_crossentropy: 0.1555 - recall: 0.9767 - val_loss: 0.1732 - val_acc: 0.9053 - val_binary_crossentropy: 1.3285 - val_recall: 0.8985\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.19583 to 0.17316, saving model to 6_result/exp_fold3/model/best.h5\n",
      "Epoch 7/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0225 - acc: 0.9811 - binary_crossentropy: 0.1493 - recall: 0.9790 - val_loss: 0.2252 - val_acc: 0.8820 - val_binary_crossentropy: 1.8127 - val_recall: 0.8136\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.17316\n",
      "Epoch 8/100\n",
      "3008/3008 [==============================] - 204s 68ms/step - loss: 0.0211 - acc: 0.9817 - binary_crossentropy: 0.1492 - recall: 0.9804 - val_loss: 0.1935 - val_acc: 0.9106 - val_binary_crossentropy: 1.4388 - val_recall: 0.7644\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.17316\n",
      "Epoch 9/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0198 - acc: 0.9826 - binary_crossentropy: 0.1471 - recall: 0.9816 - val_loss: 0.1824 - val_acc: 0.9072 - val_binary_crossentropy: 1.4654 - val_recall: 0.8362\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.17316\n",
      "Epoch 10/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0185 - acc: 0.9832 - binary_crossentropy: 0.1451 - recall: 0.9828 - val_loss: 0.2236 - val_acc: 0.8758 - val_binary_crossentropy: 2.3959 - val_recall: 0.8574\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17316\n",
      "Epoch 11/100\n",
      "3008/3008 [==============================] - 194s 64ms/step - loss: 0.0178 - acc: 0.9835 - binary_crossentropy: 0.1464 - recall: 0.9835 - val_loss: 0.2888 - val_acc: 0.8681 - val_binary_crossentropy: 2.4885 - val_recall: 0.6766\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17316\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 12/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0148 - acc: 0.9853 - binary_crossentropy: 0.1248 - recall: 0.9865 - val_loss: 0.1891 - val_acc: 0.8983 - val_binary_crossentropy: 1.9116 - val_recall: 0.8704\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17316\n",
      "Epoch 13/100\n",
      "3008/3008 [==============================] - 187s 62ms/step - loss: 0.0140 - acc: 0.9857 - binary_crossentropy: 0.1213 - recall: 0.9871 - val_loss: 0.1947 - val_acc: 0.8958 - val_binary_crossentropy: 1.9795 - val_recall: 0.8624\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17316\n",
      "Epoch 14/100\n",
      "3008/3008 [==============================] - 191s 64ms/step - loss: 0.0138 - acc: 0.9858 - binary_crossentropy: 0.1218 - recall: 0.9874 - val_loss: 0.1995 - val_acc: 0.8939 - val_binary_crossentropy: 2.0620 - val_recall: 0.8521\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17316\n",
      "Epoch 15/100\n",
      "3008/3008 [==============================] - 165s 55ms/step - loss: 0.0136 - acc: 0.9860 - binary_crossentropy: 0.1215 - recall: 0.9876 - val_loss: 0.1889 - val_acc: 0.9004 - val_binary_crossentropy: 1.9360 - val_recall: 0.8580\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17316\n",
      "Epoch 16/100\n",
      "3008/3008 [==============================] - 191s 64ms/step - loss: 0.0135 - acc: 0.9859 - binary_crossentropy: 0.1218 - recall: 0.9877 - val_loss: 0.2048 - val_acc: 0.8950 - val_binary_crossentropy: 2.0987 - val_recall: 0.8248\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17316\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 17/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0133 - acc: 0.9860 - binary_crossentropy: 0.1201 - recall: 0.9880 - val_loss: 0.2026 - val_acc: 0.8926 - val_binary_crossentropy: 2.1172 - val_recall: 0.8467\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.17316\n",
      "Epoch 18/100\n",
      "3008/3008 [==============================] - 198s 66ms/step - loss: 0.0132 - acc: 0.9861 - binary_crossentropy: 0.1203 - recall: 0.9880 - val_loss: 0.1998 - val_acc: 0.8946 - val_binary_crossentropy: 2.1028 - val_recall: 0.8478\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.17316\n",
      "Epoch 19/100\n",
      "3008/3008 [==============================] - 195s 65ms/step - loss: 0.0132 - acc: 0.9860 - binary_crossentropy: 0.1211 - recall: 0.9880 - val_loss: 0.2000 - val_acc: 0.8942 - val_binary_crossentropy: 2.0842 - val_recall: 0.8483\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.17316\n",
      "Epoch 20/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1201 - recall: 0.9880 - val_loss: 0.1950 - val_acc: 0.8966 - val_binary_crossentropy: 2.0655 - val_recall: 0.8559\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17316\n",
      "Epoch 21/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1203 - recall: 0.9881 - val_loss: 0.1954 - val_acc: 0.8967 - val_binary_crossentropy: 2.0741 - val_recall: 0.8532\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.17316\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 22/100\n",
      "3008/3008 [==============================] - 200s 67ms/step - loss: 0.0132 - acc: 0.9860 - binary_crossentropy: 0.1212 - recall: 0.9880 - val_loss: 0.1977 - val_acc: 0.8961 - val_binary_crossentropy: 2.0747 - val_recall: 0.8490\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17316\n",
      "Epoch 23/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1204 - recall: 0.9881 - val_loss: 0.1947 - val_acc: 0.8965 - val_binary_crossentropy: 2.0713 - val_recall: 0.8573\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17316\n",
      "Epoch 24/100\n",
      "3008/3008 [==============================] - 196s 65ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1203 - recall: 0.9881 - val_loss: 0.1977 - val_acc: 0.8963 - val_binary_crossentropy: 2.0561 - val_recall: 0.8474\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.17316\n",
      "Epoch 25/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0131 - acc: 0.9862 - binary_crossentropy: 0.1202 - recall: 0.9881 - val_loss: 0.1992 - val_acc: 0.8943 - val_binary_crossentropy: 2.1268 - val_recall: 0.8531\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17316\n",
      "Epoch 26/100\n",
      "3008/3008 [==============================] - 194s 65ms/step - loss: 0.0131 - acc: 0.9861 - binary_crossentropy: 0.1203 - recall: 0.9881 - val_loss: 0.1960 - val_acc: 0.8965 - val_binary_crossentropy: 2.0774 - val_recall: 0.8513\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.17316\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 00026: early stopping\n",
      "save model\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (96, 512, 512, 3) \n",
      "masks : (96, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "==============================\n",
      "------------------------------\n",
      "load unet model\n",
      "------------------------------\n",
      "------------------------------\n",
      "start training\n",
      "------------------------------\n",
      "Epoch 1/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.1574 - acc: 0.9058 - binary_crossentropy: 0.4414 - recall: 0.9076 - val_loss: 0.2101 - val_acc: 0.9080 - val_binary_crossentropy: 0.5725 - val_recall: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.21012, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 2/100\n",
      "3008/3008 [==============================] - 202s 67ms/step - loss: 0.0722 - acc: 0.9539 - binary_crossentropy: 0.2847 - recall: 0.9415 - val_loss: 0.2646 - val_acc: 0.8847 - val_binary_crossentropy: 1.0478 - val_recall: 0.6562\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.21012\n",
      "Epoch 3/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0495 - acc: 0.9664 - binary_crossentropy: 0.2313 - recall: 0.9572 - val_loss: 0.1650 - val_acc: 0.9131 - val_binary_crossentropy: 0.9218 - val_recall: 0.8797\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21012 to 0.16501, saving model to 6_result/exp_fold4/model/best.h5\n",
      "Epoch 4/100\n",
      "3008/3008 [==============================] - 204s 68ms/step - loss: 0.0389 - acc: 0.9719 - binary_crossentropy: 0.2099 - recall: 0.9652 - val_loss: 0.1792 - val_acc: 0.9011 - val_binary_crossentropy: 1.2795 - val_recall: 0.8910\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.16501\n",
      "Epoch 5/100\n",
      "3008/3008 [==============================] - 195s 65ms/step - loss: 0.0321 - acc: 0.9759 - binary_crossentropy: 0.1917 - recall: 0.9707 - val_loss: 0.1779 - val_acc: 0.9041 - val_binary_crossentropy: 1.3214 - val_recall: 0.8710\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.16501\n",
      "Epoch 6/100\n",
      "3008/3008 [==============================] - 196s 65ms/step - loss: 0.0281 - acc: 0.9781 - binary_crossentropy: 0.1830 - recall: 0.9740 - val_loss: 0.2075 - val_acc: 0.8801 - val_binary_crossentropy: 1.7045 - val_recall: 0.9066\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.16501\n",
      "Epoch 7/100\n",
      "3008/3008 [==============================] - 196s 65ms/step - loss: 0.0253 - acc: 0.9795 - binary_crossentropy: 0.1767 - recall: 0.9765 - val_loss: 0.2180 - val_acc: 0.8951 - val_binary_crossentropy: 1.6498 - val_recall: 0.7656\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16501\n",
      "Epoch 8/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0235 - acc: 0.9803 - binary_crossentropy: 0.1776 - recall: 0.9779 - val_loss: 0.1985 - val_acc: 0.9039 - val_binary_crossentropy: 1.4610 - val_recall: 0.7873\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.16501\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 9/100\n",
      "3008/3008 [==============================] - 195s 65ms/step - loss: 0.0184 - acc: 0.9833 - binary_crossentropy: 0.1454 - recall: 0.9829 - val_loss: 0.1704 - val_acc: 0.9123 - val_binary_crossentropy: 1.4330 - val_recall: 0.8557\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.16501\n",
      "Epoch 10/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0174 - acc: 0.9838 - binary_crossentropy: 0.1427 - recall: 0.9838 - val_loss: 0.1831 - val_acc: 0.9072 - val_binary_crossentropy: 1.5742 - val_recall: 0.8342\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.16501\n",
      "Epoch 11/100\n",
      "3008/3008 [==============================] - 209s 69ms/step - loss: 0.0170 - acc: 0.9840 - binary_crossentropy: 0.1416 - recall: 0.9843 - val_loss: 0.1719 - val_acc: 0.9099 - val_binary_crossentropy: 1.5350 - val_recall: 0.8652\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.16501\n",
      "Epoch 12/100\n",
      "3008/3008 [==============================] - 194s 64ms/step - loss: 0.0166 - acc: 0.9843 - binary_crossentropy: 0.1399 - recall: 0.9846 - val_loss: 0.1665 - val_acc: 0.9143 - val_binary_crossentropy: 1.4973 - val_recall: 0.8630\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.16501\n",
      "Epoch 13/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0164 - acc: 0.9844 - binary_crossentropy: 0.1395 - recall: 0.9848 - val_loss: 0.1706 - val_acc: 0.9106 - val_binary_crossentropy: 1.5752 - val_recall: 0.8661\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.16501\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 14/100\n",
      "3008/3008 [==============================] - 200s 66ms/step - loss: 0.0160 - acc: 0.9846 - binary_crossentropy: 0.1369 - recall: 0.9852 - val_loss: 0.1704 - val_acc: 0.9102 - val_binary_crossentropy: 1.5887 - val_recall: 0.8710\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.16501\n",
      "Epoch 15/100\n",
      "3008/3008 [==============================] - 201s 67ms/step - loss: 0.0158 - acc: 0.9848 - binary_crossentropy: 0.1354 - recall: 0.9854 - val_loss: 0.1712 - val_acc: 0.9104 - val_binary_crossentropy: 1.5839 - val_recall: 0.8653\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.16501\n",
      "Epoch 16/100\n",
      "3008/3008 [==============================] - 197s 65ms/step - loss: 0.0159 - acc: 0.9847 - binary_crossentropy: 0.1361 - recall: 0.9853 - val_loss: 0.1689 - val_acc: 0.9110 - val_binary_crossentropy: 1.5788 - val_recall: 0.8727\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.16501\n",
      "Epoch 17/100\n",
      "3008/3008 [==============================] - 215s 71ms/step - loss: 0.0158 - acc: 0.9847 - binary_crossentropy: 0.1354 - recall: 0.9854 - val_loss: 0.1689 - val_acc: 0.9112 - val_binary_crossentropy: 1.5692 - val_recall: 0.8708\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.16501\n",
      "Epoch 18/100\n",
      "3008/3008 [==============================] - 205s 68ms/step - loss: 0.0158 - acc: 0.9847 - binary_crossentropy: 0.1356 - recall: 0.9854 - val_loss: 0.1681 - val_acc: 0.9111 - val_binary_crossentropy: 1.5746 - val_recall: 0.8782\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16501\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 19/100\n",
      "3008/3008 [==============================] - 210s 70ms/step - loss: 0.0159 - acc: 0.9846 - binary_crossentropy: 0.1364 - recall: 0.9854 - val_loss: 0.1721 - val_acc: 0.9100 - val_binary_crossentropy: 1.5816 - val_recall: 0.8661\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16501\n",
      "Epoch 20/100\n",
      "3008/3008 [==============================] - 206s 68ms/step - loss: 0.0158 - acc: 0.9847 - binary_crossentropy: 0.1358 - recall: 0.9853 - val_loss: 0.1705 - val_acc: 0.9105 - val_binary_crossentropy: 1.5910 - val_recall: 0.8690\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16501\n",
      "Epoch 21/100\n",
      "3008/3008 [==============================] - 203s 68ms/step - loss: 0.0158 - acc: 0.9847 - binary_crossentropy: 0.1359 - recall: 0.9854 - val_loss: 0.1703 - val_acc: 0.9101 - val_binary_crossentropy: 1.5995 - val_recall: 0.8732\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16501\n",
      "Epoch 22/100\n",
      "3008/3008 [==============================] - 206s 68ms/step - loss: 0.0157 - acc: 0.9847 - binary_crossentropy: 0.1357 - recall: 0.9855 - val_loss: 0.1712 - val_acc: 0.9105 - val_binary_crossentropy: 1.5916 - val_recall: 0.8657\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16501\n",
      "Epoch 23/100\n",
      "3008/3008 [==============================] - 199s 66ms/step - loss: 0.0157 - acc: 0.9847 - binary_crossentropy: 0.1350 - recall: 0.9855 - val_loss: 0.1676 - val_acc: 0.9122 - val_binary_crossentropy: 1.5621 - val_recall: 0.8698\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16501\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 00023: early stopping\n",
      "save model\n"
     ]
    }
   ],
   "source": [
    "for foldnum in range(0,5):\n",
    "    trainset = fold[foldnum][0]\n",
    "    testset = fold[foldnum][1]\n",
    "    \n",
    "    #model 저장 위치 생성\n",
    "    #경로는 마음대로\n",
    "    #fold{} 하고 foldnum은 유지 안하면 폴드별 결과물이 다 겹쳐져버리니 주의\n",
    "    \n",
    "    sv_model_folder ='6_result/exp_fold{}/model/'.format(foldnum)\n",
    "    mkfolder(sv_model_folder)\n",
    "\n",
    "    #Train 데이터 불러오기\n",
    "\n",
    "    imgs_train, imgs_mask_train = load_data(trainset)\n",
    "    print('='*30)\n",
    "    print('-'*30)\n",
    "    print(\"load unet model\")\n",
    "    print('-'*30)\n",
    "\n",
    "    imgs_mask_train = np.expand_dims(imgs_mask_train,axis=-1)\n",
    "    imgs_mask_train.shape\n",
    "\n",
    "    imgs_train,imgs_val,imgs_mask_train,imgs_mask_val = train_test_split(imgs_train,imgs_mask_train,test_size=0.2,random_state=7)\n",
    "\n",
    "    #data 증강을 위한 generator 선언\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "    val_image_datagen = ImageDataGenerator()\n",
    "    val_mask_datagen = ImageDataGenerator()\n",
    "\n",
    "    image_generator = image_datagen.flow(imgs_train,batch_size=1,seed=1)\n",
    "    mask_generator = mask_datagen.flow(imgs_mask_train,batch_size=1,seed=1)\n",
    "\n",
    "    valt_generator = val_image_datagen.flow(imgs_val,batch_size=1,seed=1)\n",
    "    valm_generator = val_mask_datagen.flow(imgs_mask_val,batch_size=1,seed=1)\n",
    "\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    validation_generator = zip(valt_generator,valm_generator)\n",
    "    \n",
    "    \n",
    "    img_rows, img_cols=512,512\n",
    "\n",
    "\n",
    "    #주석처리한건 swin_unet의 코드\n",
    "    #적용한건 att_unet_2d 코드\n",
    "    \n",
    "    #kers_unet_collection을 이용해서 모델을 쉽게 구성하고 불러올 수 있음.\n",
    "    #다른 모델은 https://github.com/yingkaisha/keras-unet-collection에서 참조\n",
    "    \n",
    "#     model = models.swin_unet_2d((512, 512, 3), filter_num_begin=64, n_labels=1, depth=4, stack_num_down=2, stack_num_up=2, \n",
    "#                             patch_size=(2, 2), num_heads=[4, 8, 8, 8], window_size=[4, 2, 2, 2], num_mlp=512, \n",
    "#                             output_activation='Softmax', shift_window=True, name='swin_unet')\n",
    "\n",
    "    model = models.att_unet_2d((img_rows, img_cols,3), filter_num=[64, 128, 256, 512], n_labels=1, \n",
    "                               stack_num_down=2, stack_num_up=2, activation='ReLU', \n",
    "                               atten_activation='ReLU', attention='add', output_activation='Sigmoid', \n",
    "                               batch_norm=True, pool=False, unpool=False, \n",
    "                               backbone='ResNet101V2', weights='imagenet', \n",
    "                               freeze_backbone=True, freeze_batch_norm=True, \n",
    "                               name='attunet')\n",
    "    #     model = multi_gpu_model(model,gpus=4)\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "\n",
    "    # model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "    #               loss=[losses.dice,losses.dice,losses.dice,losses.dice,losses.dice,losses.dice],\n",
    "    #               loss_weights=[0.25,0.25,0.25,0.25,1,0],\n",
    "    #               metrics=['acc', 'binary_crossentropy', recall])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "                  loss=[losses.dice],\n",
    "                  metrics=['acc', 'binary_crossentropy', recall])\n",
    "\n",
    "    # reference : https://stackoverflow.com/questions/43782409/how-to-use-modelcheckpoint-with-custom-metrics-in-keras\n",
    "    # print(model.metrics_names)\n",
    "\n",
    "    # sv_model_folder ='../4_result/exp3_RGBE/model/fold{}/'.format(num)\n",
    "    # mkfolder(sv_model_folder)\n",
    "\n",
    "    # sv_pred_folder = '../4_result/exp3_HE/pred/fold{}/'.format(num)\n",
    "    # mkfolder(sv_pred_folder)\n",
    "\n",
    "    save_check_folder = sv_model_folder+'hdf5/'\n",
    "    mkfolder(save_check_folder)\n",
    "\n",
    "    def sch(epoch):\n",
    "        if epoch>30:\n",
    "            return 0.001\n",
    "        else:\n",
    "            return 0.01\n",
    "\n",
    "    epochs = 100\n",
    "    batch_size = 1\n",
    "\n",
    "    model_checkpoint = ModelCheckpoint(sv_model_folder+'best.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    sc = LearningRateScheduler(sch)\n",
    "    reduceLROnPlateau = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.1, verbose=1)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('start training')\n",
    "    print('-'*30)\n",
    "\n",
    "    # imgs_train = np.rollaxis(imgs_train, 3, 1)\n",
    "    # imgs_mask_train = np.rollaxis(imgs_mask_train, 3, 1)\n",
    "    # imgs_validation = np.rollaxis(imgs_validation, 3, 1)\n",
    "    # imgs_mask_validation = np.rollaxis(imgs_mask_validation, 3, 1)\n",
    "    \n",
    "    #steps_per_epoch를 3008로 준 이유는 train data 752장을 4배수 증강시켜서 사용했기 때문.\n",
    "    #batchsize는 1\n",
    "\n",
    "    model.fit(train_generator, steps_per_epoch=3008,epochs=epochs, verbose=1, validation_data=validation_generator,\n",
    "              validation_steps = 188,shuffle=True, callbacks=[model_checkpoint,reduceLROnPlateau,earlystopping])\n",
    "\n",
    "    print('save model')\n",
    "\n",
    "    model.save(sv_model_folder+'last.h5'.format(learning_rate, epochs))\n",
    "\n",
    "    # print('predict test data')\n",
    "    # imgs_mask_test = model.predict(imgs_test, batch_size=4, verbose=1)\n",
    "\n",
    "    # pred_file_name = sv_pred_folder +'exp1.npy'\n",
    "    # np.save(pred_file_name, imgs_mask_test)\n",
    "    # #     num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T01:45:17.294614Z",
     "start_time": "2022-01-24T01:45:17.291009Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-25T00:15:45.948465Z",
     "start_time": "2022-01-25T00:02:25.016182Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (24, 512, 512, 3) \n",
      "masks : (24, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"attunet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ResNet101V2_backbone (Functiona [(None, 256, 256, 64 1239552     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_trans_conv ( (None, 128, 128, 256 295168      ResNet101V2_backbone[0][2]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_bn (BatchNor (None, 128, 128, 256 1024        attunet_up0_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_activation ( (None, 128, 128, 256 0           attunet_up0_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_theta_x (Conv2D (None, 128, 128, 128 8320        ResNet101V2_backbone[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_phi_g (Conv2D)  (None, 128, 128, 128 32896       attunet_up0_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_add (Add)       (None, 128, 128, 128 0           attunet_up0_att_theta_x[0][0]    \n",
      "                                                                 attunet_up0_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_activation (ReL (None, 128, 128, 128 0           attunet_up0_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_psi_f (Conv2D)  (None, 128, 128, 1)  129         attunet_up0_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_sigmoid (Activa (None, 128, 128, 1)  0           attunet_up0_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_masking (Multip (None, 128, 128, 64) 0           ResNet101V2_backbone[0][1]       \n",
      "                                                                 attunet_up0_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_concat (Concatenate (None, 128, 128, 320 0           attunet_up0_decode_activation[0][\n",
      "                                                                 attunet_up0_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 737280      attunet_up0_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 589824      attunet_up0_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_trans_conv ( (None, 256, 256, 128 295040      attunet_up0_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_bn (BatchNor (None, 256, 256, 128 512         attunet_up1_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_activation ( (None, 256, 256, 128 0           attunet_up1_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_theta_x (Conv2D (None, 256, 256, 64) 4160        ResNet101V2_backbone[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_phi_g (Conv2D)  (None, 256, 256, 64) 8256        attunet_up1_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_add (Add)       (None, 256, 256, 64) 0           attunet_up1_att_theta_x[0][0]    \n",
      "                                                                 attunet_up1_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_activation (ReL (None, 256, 256, 64) 0           attunet_up1_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_psi_f (Conv2D)  (None, 256, 256, 1)  65          attunet_up1_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_sigmoid (Activa (None, 256, 256, 1)  0           attunet_up1_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_masking (Multip (None, 256, 256, 64) 0           ResNet101V2_backbone[0][0]       \n",
      "                                                                 attunet_up1_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_concat (Concatenate (None, 256, 256, 192 0           attunet_up1_decode_activation[0][\n",
      "                                                                 attunet_up1_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 221184      attunet_up1_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 147456      attunet_up1_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_trans_conv ( (None, 512, 512, 64) 73792       attunet_up1_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_bn (BatchNor (None, 512, 512, 64) 256         attunet_up2_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_activation ( (None, 512, 512, 64) 0           attunet_up2_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 36864       attunet_up2_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 256         attunet_up2_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 0           attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 36864       attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 36864       attunet_up2_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output (Conv2D)         (None, 512, 512, 1)  65          attunet_up2_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output_activation (Acti (None, 512, 512, 1)  0           attunet_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 3,769,411\n",
      "Trainable params: 2,527,043\n",
      "Non-trainable params: 1,242,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 42ms/step\n",
      "../../1. 데이터/4. 골반 분할 연구 데이터/1006_HE.png\n",
      "(24, 512, 512)\n",
      "(24, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9103\n",
      "sensitivity avg : 0.8411\n",
      "specificity avg : 0.9347\n",
      "dsc avg : 0.8241\n",
      "------------------------------\n",
      "sensitivity min: 0.4442973783249346\n",
      "specificity min: 0.8133487431378215\n",
      "dsc min: 0.5649084033698638\n",
      "acc min: 0.8229789733886719\n",
      "------------------------------\n",
      "sensitivity max: 0.9646865863224702\n",
      "specificity max: 0.9773300717368002\n",
      "dsc max: 0.9434744488977956\n",
      "acc max: 0.9655685424804688\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (24, 512, 512, 3) \n",
      "masks : (24, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"attunet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ResNet101V2_backbone (Functiona [(None, 256, 256, 64 1239552     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_trans_conv ( (None, 128, 128, 256 295168      ResNet101V2_backbone[0][2]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_bn (BatchNor (None, 128, 128, 256 1024        attunet_up0_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_activation ( (None, 128, 128, 256 0           attunet_up0_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_theta_x (Conv2D (None, 128, 128, 128 8320        ResNet101V2_backbone[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_phi_g (Conv2D)  (None, 128, 128, 128 32896       attunet_up0_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_add (Add)       (None, 128, 128, 128 0           attunet_up0_att_theta_x[0][0]    \n",
      "                                                                 attunet_up0_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_activation (ReL (None, 128, 128, 128 0           attunet_up0_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_psi_f (Conv2D)  (None, 128, 128, 1)  129         attunet_up0_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_sigmoid (Activa (None, 128, 128, 1)  0           attunet_up0_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_masking (Multip (None, 128, 128, 64) 0           ResNet101V2_backbone[0][1]       \n",
      "                                                                 attunet_up0_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_concat (Concatenate (None, 128, 128, 320 0           attunet_up0_decode_activation[0][\n",
      "                                                                 attunet_up0_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 737280      attunet_up0_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 589824      attunet_up0_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_trans_conv ( (None, 256, 256, 128 295040      attunet_up0_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_bn (BatchNor (None, 256, 256, 128 512         attunet_up1_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_activation ( (None, 256, 256, 128 0           attunet_up1_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_theta_x (Conv2D (None, 256, 256, 64) 4160        ResNet101V2_backbone[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_phi_g (Conv2D)  (None, 256, 256, 64) 8256        attunet_up1_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_add (Add)       (None, 256, 256, 64) 0           attunet_up1_att_theta_x[0][0]    \n",
      "                                                                 attunet_up1_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_activation (ReL (None, 256, 256, 64) 0           attunet_up1_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_psi_f (Conv2D)  (None, 256, 256, 1)  65          attunet_up1_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_sigmoid (Activa (None, 256, 256, 1)  0           attunet_up1_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_masking (Multip (None, 256, 256, 64) 0           ResNet101V2_backbone[0][0]       \n",
      "                                                                 attunet_up1_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_concat (Concatenate (None, 256, 256, 192 0           attunet_up1_decode_activation[0][\n",
      "                                                                 attunet_up1_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 221184      attunet_up1_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 147456      attunet_up1_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_trans_conv ( (None, 512, 512, 64) 73792       attunet_up1_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_bn (BatchNor (None, 512, 512, 64) 256         attunet_up2_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_activation ( (None, 512, 512, 64) 0           attunet_up2_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 36864       attunet_up2_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 256         attunet_up2_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 0           attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 36864       attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 36864       attunet_up2_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output (Conv2D)         (None, 512, 512, 1)  65          attunet_up2_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output_activation (Acti (None, 512, 512, 1)  0           attunet_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 3,769,411\n",
      "Trainable params: 2,527,043\n",
      "Non-trainable params: 1,242,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 50ms/step\n",
      "../../1. 데이터/4. 골반 분할 연구 데이터/1012_HE.png\n",
      "(24, 512, 512)\n",
      "(24, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.8977\n",
      "sensitivity avg : 0.9349\n",
      "specificity avg : 0.8853\n",
      "dsc avg : 0.8335\n",
      "------------------------------\n",
      "sensitivity min: 0.8039102185469581\n",
      "specificity min: 0.6961418414143576\n",
      "dsc min: 0.6432539456441229\n",
      "acc min: 0.7309417724609375\n",
      "------------------------------\n",
      "sensitivity max: 0.9854019376800209\n",
      "specificity max: 0.978493424321392\n",
      "dsc max: 0.9437962009308632\n",
      "acc max: 0.96923828125\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (24, 512, 512, 3) \n",
      "masks : (24, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"attunet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ResNet101V2_backbone (Functiona [(None, 256, 256, 64 1239552     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_trans_conv ( (None, 128, 128, 256 295168      ResNet101V2_backbone[0][2]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_bn (BatchNor (None, 128, 128, 256 1024        attunet_up0_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_activation ( (None, 128, 128, 256 0           attunet_up0_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_theta_x (Conv2D (None, 128, 128, 128 8320        ResNet101V2_backbone[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_phi_g (Conv2D)  (None, 128, 128, 128 32896       attunet_up0_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_add (Add)       (None, 128, 128, 128 0           attunet_up0_att_theta_x[0][0]    \n",
      "                                                                 attunet_up0_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_activation (ReL (None, 128, 128, 128 0           attunet_up0_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_psi_f (Conv2D)  (None, 128, 128, 1)  129         attunet_up0_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_sigmoid (Activa (None, 128, 128, 1)  0           attunet_up0_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_masking (Multip (None, 128, 128, 64) 0           ResNet101V2_backbone[0][1]       \n",
      "                                                                 attunet_up0_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_concat (Concatenate (None, 128, 128, 320 0           attunet_up0_decode_activation[0][\n",
      "                                                                 attunet_up0_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 737280      attunet_up0_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 589824      attunet_up0_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_trans_conv ( (None, 256, 256, 128 295040      attunet_up0_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_bn (BatchNor (None, 256, 256, 128 512         attunet_up1_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_activation ( (None, 256, 256, 128 0           attunet_up1_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_theta_x (Conv2D (None, 256, 256, 64) 4160        ResNet101V2_backbone[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_phi_g (Conv2D)  (None, 256, 256, 64) 8256        attunet_up1_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_add (Add)       (None, 256, 256, 64) 0           attunet_up1_att_theta_x[0][0]    \n",
      "                                                                 attunet_up1_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_activation (ReL (None, 256, 256, 64) 0           attunet_up1_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_psi_f (Conv2D)  (None, 256, 256, 1)  65          attunet_up1_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_sigmoid (Activa (None, 256, 256, 1)  0           attunet_up1_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_masking (Multip (None, 256, 256, 64) 0           ResNet101V2_backbone[0][0]       \n",
      "                                                                 attunet_up1_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_concat (Concatenate (None, 256, 256, 192 0           attunet_up1_decode_activation[0][\n",
      "                                                                 attunet_up1_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 221184      attunet_up1_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 147456      attunet_up1_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_trans_conv ( (None, 512, 512, 64) 73792       attunet_up1_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_bn (BatchNor (None, 512, 512, 64) 256         attunet_up2_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_activation ( (None, 512, 512, 64) 0           attunet_up2_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 36864       attunet_up2_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 256         attunet_up2_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 0           attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 36864       attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 36864       attunet_up2_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output (Conv2D)         (None, 512, 512, 1)  65          attunet_up2_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output_activation (Acti (None, 512, 512, 1)  0           attunet_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 3,769,411\n",
      "Trainable params: 2,527,043\n",
      "Non-trainable params: 1,242,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 49ms/step\n",
      "../../1. 데이터/4. 골반 분할 연구 데이터/1003_HE.png\n",
      "(24, 512, 512)\n",
      "(24, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9200\n",
      "sensitivity avg : 0.8812\n",
      "specificity avg : 0.9316\n",
      "dsc avg : 0.8475\n",
      "------------------------------\n",
      "sensitivity min: 0.7010625479241976\n",
      "specificity min: 0.7782619052345316\n",
      "dsc min: 0.6186716331776927\n",
      "acc min: 0.7781829833984375\n",
      "------------------------------\n",
      "sensitivity max: 0.9551787637677635\n",
      "specificity max: 0.9933528344813848\n",
      "dsc max: 0.9597302463435063\n",
      "acc max: 0.9785423278808594\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (24, 512, 512, 3) \n",
      "masks : (24, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"attunet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ResNet101V2_backbone (Functiona [(None, 256, 256, 64 1239552     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_trans_conv ( (None, 128, 128, 256 295168      ResNet101V2_backbone[0][2]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_bn (BatchNor (None, 128, 128, 256 1024        attunet_up0_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_activation ( (None, 128, 128, 256 0           attunet_up0_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_theta_x (Conv2D (None, 128, 128, 128 8320        ResNet101V2_backbone[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_phi_g (Conv2D)  (None, 128, 128, 128 32896       attunet_up0_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_add (Add)       (None, 128, 128, 128 0           attunet_up0_att_theta_x[0][0]    \n",
      "                                                                 attunet_up0_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_activation (ReL (None, 128, 128, 128 0           attunet_up0_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_psi_f (Conv2D)  (None, 128, 128, 1)  129         attunet_up0_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_sigmoid (Activa (None, 128, 128, 1)  0           attunet_up0_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_masking (Multip (None, 128, 128, 64) 0           ResNet101V2_backbone[0][1]       \n",
      "                                                                 attunet_up0_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_concat (Concatenate (None, 128, 128, 320 0           attunet_up0_decode_activation[0][\n",
      "                                                                 attunet_up0_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 737280      attunet_up0_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 589824      attunet_up0_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_trans_conv ( (None, 256, 256, 128 295040      attunet_up0_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_bn (BatchNor (None, 256, 256, 128 512         attunet_up1_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_activation ( (None, 256, 256, 128 0           attunet_up1_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_theta_x (Conv2D (None, 256, 256, 64) 4160        ResNet101V2_backbone[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_phi_g (Conv2D)  (None, 256, 256, 64) 8256        attunet_up1_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_add (Add)       (None, 256, 256, 64) 0           attunet_up1_att_theta_x[0][0]    \n",
      "                                                                 attunet_up1_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_activation (ReL (None, 256, 256, 64) 0           attunet_up1_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_psi_f (Conv2D)  (None, 256, 256, 1)  65          attunet_up1_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_sigmoid (Activa (None, 256, 256, 1)  0           attunet_up1_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_masking (Multip (None, 256, 256, 64) 0           ResNet101V2_backbone[0][0]       \n",
      "                                                                 attunet_up1_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_concat (Concatenate (None, 256, 256, 192 0           attunet_up1_decode_activation[0][\n",
      "                                                                 attunet_up1_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 221184      attunet_up1_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 147456      attunet_up1_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_trans_conv ( (None, 512, 512, 64) 73792       attunet_up1_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_bn (BatchNor (None, 512, 512, 64) 256         attunet_up2_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_activation ( (None, 512, 512, 64) 0           attunet_up2_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 36864       attunet_up2_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 256         attunet_up2_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 0           attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 36864       attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 36864       attunet_up2_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output (Conv2D)         (None, 512, 512, 1)  65          attunet_up2_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output_activation (Acti (None, 512, 512, 1)  0           attunet_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 3,769,411\n",
      "Trainable params: 2,527,043\n",
      "Non-trainable params: 1,242,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 49ms/step\n",
      "../../1. 데이터/4. 골반 분할 연구 데이터/1000000_HE.png\n",
      "(24, 512, 512)\n",
      "(24, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9016\n",
      "sensitivity avg : 0.9114\n",
      "specificity avg : 0.8951\n",
      "dsc avg : 0.8419\n",
      "------------------------------\n",
      "sensitivity min: 0.7507488284458186\n",
      "specificity min: 0.669425723888465\n",
      "dsc min: 0.7206874152194265\n",
      "acc min: 0.7699508666992188\n",
      "------------------------------\n",
      "sensitivity max: 0.9820494129285882\n",
      "specificity max: 0.981065949247437\n",
      "dsc max: 0.9423987398341608\n",
      "acc max: 0.9751701354980469\n",
      "------------------------------\n",
      "load images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "imgs : (24, 512, 512, 3) \n",
      "masks : (24, 512, 512)\n",
      "------------------------------\n",
      "img :  255.0\n",
      "mask :  255.0\n",
      "------------------------------\n",
      "normalization start...\n",
      "------------------------------\n",
      "img :  1.0\n",
      "mask :  1.0\n",
      "Model: \"attunet_model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ResNet101V2_backbone (Functiona [(None, 256, 256, 64 1239552     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_trans_conv ( (None, 128, 128, 256 295168      ResNet101V2_backbone[0][2]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_bn (BatchNor (None, 128, 128, 256 1024        attunet_up0_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_decode_activation ( (None, 128, 128, 256 0           attunet_up0_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_theta_x (Conv2D (None, 128, 128, 128 8320        ResNet101V2_backbone[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_phi_g (Conv2D)  (None, 128, 128, 128 32896       attunet_up0_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_add (Add)       (None, 128, 128, 128 0           attunet_up0_att_theta_x[0][0]    \n",
      "                                                                 attunet_up0_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_activation (ReL (None, 128, 128, 128 0           attunet_up0_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_psi_f (Conv2D)  (None, 128, 128, 1)  129         attunet_up0_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_sigmoid (Activa (None, 128, 128, 1)  0           attunet_up0_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_att_masking (Multip (None, 128, 128, 64) 0           ResNet101V2_backbone[0][1]       \n",
      "                                                                 attunet_up0_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_concat (Concatenate (None, 128, 128, 320 0           attunet_up0_decode_activation[0][\n",
      "                                                                 attunet_up0_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 737280      attunet_up0_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_0 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 589824      attunet_up0_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 1024        attunet_up0_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up0_conv_after_concat_1 (None, 128, 128, 256 0           attunet_up0_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_trans_conv ( (None, 256, 256, 128 295040      attunet_up0_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_bn (BatchNor (None, 256, 256, 128 512         attunet_up1_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_decode_activation ( (None, 256, 256, 128 0           attunet_up1_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_theta_x (Conv2D (None, 256, 256, 64) 4160        ResNet101V2_backbone[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_phi_g (Conv2D)  (None, 256, 256, 64) 8256        attunet_up1_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_add (Add)       (None, 256, 256, 64) 0           attunet_up1_att_theta_x[0][0]    \n",
      "                                                                 attunet_up1_att_phi_g[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_activation (ReL (None, 256, 256, 64) 0           attunet_up1_att_add[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_psi_f (Conv2D)  (None, 256, 256, 1)  65          attunet_up1_att_activation[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_sigmoid (Activa (None, 256, 256, 1)  0           attunet_up1_att_psi_f[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_att_masking (Multip (None, 256, 256, 64) 0           ResNet101V2_backbone[0][0]       \n",
      "                                                                 attunet_up1_att_sigmoid[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_concat (Concatenate (None, 256, 256, 192 0           attunet_up1_decode_activation[0][\n",
      "                                                                 attunet_up1_att_masking[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 221184      attunet_up1_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_0 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 147456      attunet_up1_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 512         attunet_up1_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up1_conv_after_concat_1 (None, 256, 256, 128 0           attunet_up1_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_trans_conv ( (None, 512, 512, 64) 73792       attunet_up1_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_bn (BatchNor (None, 512, 512, 64) 256         attunet_up2_decode_trans_conv[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_decode_activation ( (None, 512, 512, 64) 0           attunet_up2_decode_bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 36864       attunet_up2_decode_activation[0][\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 256         attunet_up2_conv_before_concat_0[\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_before_concat_ (None, 512, 512, 64) 0           attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 36864       attunet_up2_conv_before_concat_0_\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_0[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_0 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_0_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 36864       attunet_up2_conv_after_concat_0_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 256         attunet_up2_conv_after_concat_1[0\n",
      "__________________________________________________________________________________________________\n",
      "attunet_up2_conv_after_concat_1 (None, 512, 512, 64) 0           attunet_up2_conv_after_concat_1_b\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output (Conv2D)         (None, 512, 512, 1)  65          attunet_up2_conv_after_concat_1_a\n",
      "__________________________________________________________________________________________________\n",
      "attunet_output_activation (Acti (None, 512, 512, 1)  0           attunet_output[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 3,769,411\n",
      "Trainable params: 2,527,043\n",
      "Non-trainable params: 1,242,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 50ms/step\n",
      "../../1. 데이터/4. 골반 분할 연구 데이터/1007_HE.png\n",
      "(24, 512, 512)\n",
      "(24, 512, 512, 1)\n",
      "complete\n",
      "acc avg : 0.9105\n",
      "sensitivity avg : 0.8587\n",
      "specificity avg : 0.9307\n",
      "dsc avg : 0.8390\n",
      "------------------------------\n",
      "sensitivity min: 0.6885028540608567\n",
      "specificity min: 0.8214980544747081\n",
      "dsc min: 0.6925764562763459\n",
      "acc min: 0.8341903686523438\n",
      "------------------------------\n",
      "sensitivity max: 0.9419083746717245\n",
      "specificity max: 0.9926017048998544\n",
      "dsc max: 0.9266906125094523\n",
      "acc max: 0.9672698974609375\n"
     ]
    }
   ],
   "source": [
    "# 각 fold별로 생성된 모델의 성능을 측정하는 부분\n",
    "\n",
    "for foldnum in range(5):\n",
    "    \n",
    "    testset = fold[foldnum][1]\n",
    "    imgs_test, imgs_mask_test = load_data(testset)\n",
    "    model = load_model('6_result/exp_fold{}/model/best.h5'.format(foldnum), custom_objects={\"dice\": losses.dice, 'recall':recall})\n",
    "    print(model.summary())\n",
    "    # imgs_test, imgs_mask_test = load_data(testset[:4])\n",
    "    mask_pred = model.predict(imgs_test, batch_size=4, verbose=1)\n",
    "\n",
    "    print(testset[0])\n",
    "    # true_list=np.load(testset[0])\n",
    "    true_list = imgs_mask_test\n",
    "    true_list=true_list.astype('float32')\n",
    "    # true_list = true_list/255.0\n",
    "    # true_list[true_list > 0.5] = 1\n",
    "    # true_list[true_list <= 0.5] = 0\n",
    "    print(true_list.shape)\n",
    "\n",
    "    pred_list=mask_pred\n",
    "    # pred_list=imgs_mask_test\n",
    "    pred_list[pred_list > 0.5] = 1\n",
    "    pred_list[pred_list <= 0.5] = 0\n",
    "    print(pred_list.shape)\n",
    "\n",
    "    # for i in range(pred_list.shape[0]):\n",
    "    #     pred = pred_list[i].astype('uint8')\n",
    "    #     pred[pred <= 0.5] = 0\n",
    "    #     pred[pred > 0.5] = 255\n",
    "    # #     pred = fill_hole_cv(pred)\n",
    "    #     pred_list[i]=pred\n",
    "\n",
    "    # pred_list[pred_list > 127] = 1\n",
    "    # pred_list[pred_list <= 127] = 0\n",
    "\n",
    "    sensitivity=[]\n",
    "    specificity=[]\n",
    "    acc=[]\n",
    "    dsc=[]\n",
    "\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i].flatten()\n",
    "        yp=pred_list[i].flatten()\n",
    "        mat=confusion_matrix(yt,yp)\n",
    "        if len(mat) == 2:\n",
    "            ac=(mat[1,1]+mat[0,0])/(mat[1,0]+mat[1,1]+mat[0,1]+mat[0,0])\n",
    "            st=mat[1,1]/(mat[1,0]+mat[1,1])\n",
    "            sp=mat[0,0]/(mat[0,1]+mat[0,0])\n",
    "            if mat[1,0]+mat[1,1] == 0:\n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "            else:\n",
    "                sensitivity.append(st)  \n",
    "                specificity.append(sp)\n",
    "                acc.append(ac)\n",
    "        else:\n",
    "            specificity.append(1)\n",
    "            acc.append(1)\n",
    "\n",
    "    for i in range(len(true_list)):\n",
    "        yt=true_list[i]\n",
    "        yp=pred_list[i]\n",
    "        if np.sum(yt) != 0 and np.sum(yp) != 0:\n",
    "            dice = np.sum(yp[yt==1])*2.0 / (np.sum(yt) + np.sum(yp))\n",
    "            dsc.append(dice)\n",
    "\n",
    "    print(\"complete\")      \n",
    "    print(\"acc avg : {0:0.4f}\".format(np.mean(acc)))\n",
    "    print(\"sensitivity avg : {0:0.4f}\".format(np.mean(sensitivity)))\n",
    "    print(\"specificity avg : {0:0.4f}\".format(np.mean(specificity)))\n",
    "    print(\"dsc avg : {0:0.4f}\".format(np.mean(dsc)))\n",
    "    print('-'*30)\n",
    "    print(\"sensitivity min:\",np.min(sensitivity))\n",
    "    print(\"specificity min:\",np.min(specificity))\n",
    "    print(\"dsc min:\",np.min(dsc))\n",
    "    print(\"acc min:\",np.min(acc))\n",
    "    print('-'*30)\n",
    "    print(\"sensitivity max:\",np.max(sensitivity))\n",
    "    print(\"specificity max:\",np.max(specificity))\n",
    "    print(\"dsc max:\",np.max(dsc))\n",
    "    print(\"acc max:\",np.max(acc))\n",
    "    \n",
    "    imgs_test, imgs_mask_test = 0,0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
